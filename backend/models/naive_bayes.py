import pandas as pd
import io
import joblib
df = pd.read_csv(r'd:\ModelViz\backend\static\SpamTextCSV.csv')
# print(df.head())

"""Undersampling"""

import numpy as np
#compute the length of majority & minority class
minority_len=len(df[df["Category"]=="spam"])
majority_len=len(df[df["Category"]=="ham"])

#store the indices of majority and minority class
minority_indices=df[df["Category"]=="spam"].index
majority_indices=df[df["Category"]=="ham"].index

#generate new majority indices from the total majority_indices
#with size equal to minority class length so we obtain equivalent number of indices length
random_majority_indices=np.random.choice(
    majority_indices,
    size=minority_len,
    replace=False
)
#concatenate the two indices to obtain indices of new dataframe
undersampled_indices=np.concatenate([minority_indices,random_majority_indices])

# print(undersampled_indices)
#create df using new indices
data=df.loc[undersampled_indices]

#shuffle the sample
data=data.sample(frac=1)

#reset the index as its all mixed
data=data.reset_index()

#drop the older index
data=data.drop(
    columns=["index"],
)

data.shape
data["Category"].value_counts()

data['spam'] = data['Category'].apply(lambda x:1 if x=='spam' else 0)
# data.head()

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(data.Message, data.spam, test_size=0.15, random_state = 42)

from sklearn.feature_extraction.text import CountVectorizer
v = CountVectorizer()
X_train_count = v.fit_transform(X_train.values)
# joblib.dump(v, 'countVectorizer.pkl')
X_train_count.toarray()[:3]

from sklearn.naive_bayes import MultinomialNB
model = MultinomialNB()
model.fit(X_train_count, y_train)

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
X_test_count = v.transform(X_test)  # Transform test data using the fitted CountVectorizer
y_pred = model.predict(X_test_count)  # Predict using the trained model
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)
print("Accuracy: ", accuracy)
print("Precision: ",precision)
print("Accuracy: ",accuracy)
print("F1 score: ",f1)
metrics_nb = {
    "accuracy": accuracy,
    "precision": precision,
    "recall": recall,
    "f1" : f1
}
joblib.dump(metrics_nb, 'metrics_nb.pkl')
print("done")
# joblib.dump(model, 'naivebayes_joblib.pkl')